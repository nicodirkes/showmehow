#!/usr/bin/env nextflow

workflow {

  


    LHS (
        params.LHS
        )
    
    FORWARD_MODEL (
        LHS.out,
        file("$moduleDir/forward_model/synthetic_topo.asc") // TODO: Should be a config parameter
        )
    
    TRAIN_SURROGATE (
        LHS.out,
        FORWARD_MODEL.out
        )
  
    UQ_STATUS (
        TRAIN_SURROGATE.out.done
        ) 
    
    SERVE_SURROGATE ( 
        UQ_STATUS.out.pipe,
        file("$moduleDir/surrogate/serve_surrogate.R"),
        TRAIN_SURROGATE.out.model,
        "ScalarGP_Umax",
        port_number = 4242
        ) 

    MCMC ( 
        UQ_STATUS.out.pipe,
        file("$moduleDir/mcmc/MCMC_um.py"),
        "ScalarGP_Umax",
        file("$moduleDir/mcmc/calibration_data.csv")
        ) 

    // LHS_ext_jl(
    //     file("$moduleDir/lhs/sampling.jl"),
    //     setupLHS.out,
    //     )
}


process LHS {

    container "file://$moduleDir/lhs/lhs_box.sif"
    publishDir "$moduleDir/outputs", mode: 'copy'
    

    input:
      val parameters

    output:
      file "lhs_output.csv"

    script:
    """
    #!/usr/bin/env julia 

    using QuasiMonteCarlo, Distributions
    using CSV
    using DataFrames


    d = ${parameters.bounds.size()}
    lb = [${parameters.bounds.parameter1[0]}, ${parameters.bounds.parameter2[0]}]
    ub = [${parameters.bounds.parameter1[1]}, ${parameters.bounds.parameter2[1]}]
    n = ${parameters.samples}  # Number of samples


    # # Generate LHS samples
    s = QuasiMonteCarlo.sample(n, lb, ub, LatinHypercubeSample())

    # # Convert to DataFrame (transpose and convert to regular matrix)
    df = DataFrame(Matrix(s'), :auto)  # Specify :auto for automatic column names


    # # Save the DataFrame to a CSV file without headers
    CSV.write("lhs_output.csv", df)


    """ 
}

process FORWARD_MODEL {
    container "file://$moduleDir/forward_model/forward_model.sif"
    publishDir "$moduleDir/outputs", mode: 'copy'

    
    input:
      path lhs_samples
      path elevation_file

    output:
      file "Umax_MPM.csv" 

    script:
    """
    #!/usr/bin/env python3

    from psimpy.simulator import MassPointModel
    from psimpy.simulator import RunSimulator
    import numpy as np

    # Load the LHS samples
    train_samples = np.loadtxt("$lhs_samples", delimiter=',', skiprows=1)
    nsamples = train_samples.shape[0] 

    

    # Setup Mass Point Model
    MPM_M1 = MassPointModel()

    simulator = RunSimulator(
        simulator=MPM_M1.run,
        var_inp_parameter=[
            'coulomb_friction',
            'turbulent_friction'
            ],
        fix_inp={
            'elevation' : "$elevation_file",
            'x0' : 200,  # TODO Move to config parameter
            'y0' : 2000, # TODO Move to config parameter
            'dt' : 0.1   # TODO Move to config parameter
            }
        )

    # Run the simulations
    simulator.parallel_run(var_samples=train_samples)
    serial_output = simulator.outputs

    # Post-process the results
    U_res = np.ones(nsamples)
    # x_res = np.ones(nsamples)
    for i in range(nsamples):
            U_res[i] = serial_output[i][:,5].max()
            # x_res[i] = serial_output[i][:,1].max()

    np.savetxt("Umax_MPM.csv", U_res, delimiter=",")
    
    """
}

process TRAIN_SURROGATE {
    container "file://$moduleDir/surrogate/surrogate.sif"
    publishDir "$moduleDir/outputs", mode: 'copy'


    input:
    path design
    path response

    output:
    path "ScalarGP_Umax.rds",  emit: model
    val true, emit: done

    script:
        """
        #!/usr/bin/env Rscript
        library("RobustGaSP")


        # Read input data
        design <- as.matrix(read.csv(file.path("$design"), header = TRUE))
        print(design)


        # Read output data
        response <- as.matrix(read.csv(file.path("$response"), header = FALSE))
        print(response)

        # Fit the Gaussian process model
        ScalarGP_Umax <- rgasp(design = design, response = response, lower_bound = TRUE)


        LOO <- leave_one_out_rgasp(ScalarGP_Umax)
        print(LOO)

        # Save the trained model using saveRDS
        saveRDS(ScalarGP_Umax, file = file.path("ScalarGP_Umax.rds"))

        """
}

process UQ_STATUS {
    input:
    val ready

    script:
    """
    mkfifo status_info
    """

    output:
    path "status_info", emit: pipe
}

process SERVE_SURROGATE {
    conda "$moduleDir/surrogate/environment.yml"
    cache 'lenient'

    input:
    path status
    path script
    path model
    val model_name
    val port_number

    script:
    """
    #!/bin/bash


    # Start the model server in the background
    Rscript ${script} ${model} ${model_name}  & 
    PID=\$!
    echo \$PID
    # Wait for the model server to start
    while ! nc -z localhost ${port_number}; do
        sleep 1
    done
    echo "model_server_up" > $status
    echo "Model server is up and running on port ${port_number}"

    # Monitor the status 
    cat $status  &
    STATUS_PID=\$!
    wait \$STATUS_PID

    # Stop the model server when the signal is received
    kill \$PID
    
    """
}

process MCMC {
    conda "$moduleDir/mcmc/environment.yml"
    cache 'lenient'
    debug true
    publishDir "$moduleDir/outputs", mode: 'copy'
    
    input:
    path status
    path script
    val model_name
    path calibration_data


    script:
    """
    cat $status # blocked until the model server is up

    python ${script} ${calibration_data} ${model_name}
    
    echo "mcmc_done" > $status # signal to stop the model server
    """

    output:
    path "mcmc_trace.npy"
    path "mcmc_full_chain.npy"
}

process LHS_ext_jl {

    container "file://$moduleDir/lhs/lhs_box.sif"

    publishDir "$moduleDir/outputs", mode: 'copy'
    

    input:
      path jl_script
      path in

    output:
      file "lhs_output.csv"

    script:
    """
    
    julia --history-file=no ${jl_script} ${in} lhs_output.csv

    """ 
}