#!/usr/bin/env nextflow

workflow {
    LHS (
        params.LHS
        )
    
    FORWARD_MODEL (
        LHS.out,
        file("$moduleDir/forward_model/synthetic_topo.asc")
        )

    TRAIN_SURROGATE (
        LHS.out,
        FORWARD_MODEL.out
        )

    UQ_STATUS (
        TRAIN_SURROGATE.out.done
        ) 
    
    SERVE_SURROGATE ( 
        UQ_STATUS.out.pipe,
        file("$moduleDir/surrogate/serve_surrogate.R"),
        TRAIN_SURROGATE.out.model,
        "ScalarGP_Umax",
        port_number = 4242
        )

    MCMC ( 
        UQ_STATUS.out.pipe,
        file("$moduleDir/mcmc/MCMC_um.py"),
        "ScalarGP_Umax",
        file("$moduleDir/mcmc/calibration_data.csv")
        ) 
}

process LHS {

    container "file://$moduleDir/lhs/lhs.sif"
    publishDir "$moduleDir/outputs", mode: 'copy'
    

    input:
      val parameters

    output:
      file "lhs_output.csv"

    script:
        """
        #!/usr/bin/env julia 

        using QuasiMonteCarlo, Distributions
        using CSV
        using DataFrames


        d = ${parameters.bounds.size()}
        lb = [${parameters.bounds.parameter1[0]}, ${parameters.bounds.parameter2[0]}]
        ub = [${parameters.bounds.parameter1[1]}, ${parameters.bounds.parameter2[1]}]
        n = ${parameters.samples}  # Number of samples


        # # Generate LHS samples
        s = QuasiMonteCarlo.sample(n, lb, ub, LatinHypercubeSample())

        # # Convert to DataFrame (transpose and convert to regular matrix)
        df = DataFrame(Matrix(s'), :auto)  # Specify :auto for automatic column names


        # # Save the DataFrame to a CSV file without headers
        CSV.write("lhs_output.csv", df)


        """ 
}
process FORWARD_MODEL {
    container "file://$moduleDir/forward_model/forward_model.sif"
    publishDir "$moduleDir/outputs", mode: 'copy'

    
    input:
      path lhs_samples
      path elevation_file

    output:
      file "Umax_MPM.csv" 

    script:
        """
        #!/usr/bin/env python3

        from psimpy.simulator import MassPointModel
        from psimpy.simulator import RunSimulator
        import numpy as np

        # Load the LHS samples
        train_samples = np.loadtxt("$lhs_samples", delimiter=',', skiprows=1)
        nsamples = train_samples.shape[0] 

        

        # Setup Mass Point Model
        MPM_M1 = MassPointModel()

        simulator = RunSimulator(
            simulator=MPM_M1.run,
            var_inp_parameter=[
                'coulomb_friction',
                'turbulent_friction'
                ],
            fix_inp={
                'elevation' : "$elevation_file",
                'x0' : 200,  # TODO Move to config parameter
                'y0' : 2000, # TODO Move to config parameter
                'dt' : 0.1   # TODO Move to config parameter
                }
            )

        # Run the simulations
        simulator.parallel_run(var_samples=train_samples)
        serial_output = simulator.outputs

        # Post-process the results
        U_res = np.ones(nsamples)
        # x_res = np.ones(nsamples)
        for i in range(nsamples):
                U_res[i] = serial_output[i][:,5].max()
                # x_res[i] = serial_output[i][:,1].max()

        np.savetxt("Umax_MPM.csv", U_res, delimiter=",")
        
        """
}
process TRAIN_SURROGATE {
    container "file://$moduleDir/surrogate/surrogate.sif"
    publishDir "$moduleDir/outputs", mode: 'copy'

    input:
    path design
    path response

    output:
    path "ScalarGP_Umax.rds",  emit: model
    val true, emit: done

    script:
        """
        #!/usr/bin/env Rscript
        library("RobustGaSP")

        # Read input data
        design <- as.matrix(read.csv(file.path("$design"), header = TRUE))
        print(design)

        # Read output data
        response <- as.matrix(read.csv(file.path("$response"), header = FALSE))
        print(response)

        # Fit the Gaussian process model
        ScalarGP_Umax <- rgasp(design = design, response = response, lower_bound = TRUE)

        LOO <- leave_one_out_rgasp(ScalarGP_Umax)
        print(LOO)

        # Save the trained model using saveRDS
        saveRDS(ScalarGP_Umax, file = file.path("ScalarGP_Umax.rds"))

        """
}
process UQ_STATUS {
    input:
    val ready

    script:
    """
    mkfifo status_info
    """

    output:
    path "status_info", emit: pipe
}
process SERVE_SURROGATE {
    conda "$moduleDir/surrogate/environment.yml"
    cache 'lenient'

    input:
    path status
    path script
    path model
    val model_name
    val port_number

    script:
    """
    #!/bin/bash


    # Start the model server in the background
    Rscript ${script} ${model} ${model_name}  & 
    PID=\$!
    echo \$PID
    # Wait for the model server to start
    while ! nc -z localhost ${port_number}; do
        sleep 1
    done
    echo "model_server_up" > $status
    echo "Model server is up and running on port ${port_number}"

    # Monitor the status 
    cat $status  &
    STATUS_PID=\$!
    wait \$STATUS_PID

    # Stop the model server when the signal is received
    kill \$PID
    
    """
}
process MCMC {
    conda "$moduleDir/mcmc/environment.yml"
    cache 'lenient'
    publishDir "$moduleDir/outputs", mode: 'copy'
    
    input:
        path status
        path script
        val model_name
        path calibration_data


    script:
        """
        cat $status # blocked until the model server is up

        python ${script} ${calibration_data} ${model_name}
        
        echo "mcmc_done" > $status # signal to stop the model server
        """

    output:
    path "mcmc_trace.npy"
    path "mcmc_full_chain.npy"
}